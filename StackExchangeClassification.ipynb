{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scraping and Text Classification of Questions Asked on Stack Exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our web scraping functions defined in the SEData package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SEData.data import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate a list of question URLs from Stack Exchange's current \"Hot Network Questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_links = populate_question_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use the get_text function to return a tuple of the SE category and question text corresponding to any SE question URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('academia',\n",
       " ' Im writing a mathematical paper In it I use a lemma The lemma is not hard to prove and I have verified it myself The proof is too tedious to include in the paper so I want to just include a citation I found a paper that includes the result However that paper does not actually include a proof I cannot find any other place where this lemma appears I see three options  State the lemma without proof or citation State the lemma without proof but cite the paper that states the lemma without proof or citation Provide a proof of the lemma  Which is most appropriate Option  is easiest but might annoy some readers who dont believe me Option  seems like a cop out Option  is safest but I dont think its necessary as the proof is really just a long and boring calculation ADDED To be clear the lemma is basically an integral The proof consists of splitting up the domain of integration to remove absolute values evaluating each of the parts easy enough for symbolic integration packages like mathematica and then joining them back up This is obvious but messy because the expressions are quite long My writeup is two pages Maybe a better way to phrase my question The result is trivial  I think so the authors of the other paper think so and the journal they published in thinks so Should I still provide a citation Is it misleading to cite the other paper without clarifying that it doesnt provide a proof ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(question_links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can create a small corpus of 50 questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [get_text(link) for link in question_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.dropna(axis = 0, how = 'any', inplace = True) #Drop NAs in place. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAs occur for a given url if there is no question text (if the question was removed by moderators) or if the page hasn't been created yet (if the ID is higher than the ID of the most recently asked quesiton within a given SE category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data[0]\n",
    "corpus = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Im writing a mathematical paper In it I use a...\n",
      "1     I am a childless female something who occasio...\n",
      "2     Background I have been living with my boyfrie...\n",
      "3     I would like to know about the time format wh...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can create a sparse matrix of Term Frequency, Inverse Document Frequency scores for each word in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', max_features = 500) #Limit number of features at 500 words with highest Tfidf score\n",
    "sparse_matrix = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'absolute',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'added',\n",
       " 'address',\n",
       " 'adult',\n",
       " 'afraid',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'alloys',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'approx',\n",
       " 'argument',\n",
       " 'array',\n",
       " 'ascending',\n",
       " 'ascent',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assume',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'ax',\n",
       " 'background',\n",
       " 'based',\n",
       " 'basevalue',\n",
       " 'basically',\n",
       " 'battle',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bismuth',\n",
       " 'bit',\n",
       " 'block',\n",
       " 'body',\n",
       " 'bounce',\n",
       " 'brand',\n",
       " 'buy',\n",
       " 'car',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cast',\n",
       " 'cdot',\n",
       " 'center',\n",
       " 'certain',\n",
       " 'change',\n",
       " 'characters',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chores',\n",
       " 'citation',\n",
       " 'class',\n",
       " 'classoption',\n",
       " 'clear',\n",
       " 'closed',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comment',\n",
       " 'common',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'component',\n",
       " 'components',\n",
       " 'consequences',\n",
       " 'constant',\n",
       " 'contentaddclassoptionno',\n",
       " 'cooking',\n",
       " 'countries',\n",
       " 'course',\n",
       " 'cut',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'decelerate',\n",
       " 'decided',\n",
       " 'decimal',\n",
       " 'delta',\n",
       " 'depends',\n",
       " 'descending',\n",
       " 'details',\n",
       " 'diagram',\n",
       " 'did',\n",
       " 'different',\n",
       " 'direction',\n",
       " 'discussion',\n",
       " 'docker',\n",
       " 'does',\n",
       " 'doesnt',\n",
       " 'doing',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'draw',\n",
       " 'dynamically',\n",
       " 'earlier',\n",
       " 'eat',\n",
       " 'edit',\n",
       " 'eeeee',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'english',\n",
       " 'environment',\n",
       " 'epot',\n",
       " 'equal',\n",
       " 'equivalent',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'exactly',\n",
       " 'examiner',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'exception',\n",
       " 'executable',\n",
       " 'exert',\n",
       " 'exhausting',\n",
       " 'exist',\n",
       " 'exotic',\n",
       " 'expend',\n",
       " 'explain',\n",
       " 'expressions',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fall',\n",
       " 'false',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'female',\n",
       " 'fh',\n",
       " 'fight',\n",
       " 'file',\n",
       " 'finally',\n",
       " 'fine',\n",
       " 'fixed',\n",
       " 'flight',\n",
       " 'following',\n",
       " 'force',\n",
       " 'forever',\n",
       " 'format',\n",
       " 'free',\n",
       " 'friction',\n",
       " 'friends',\n",
       " 'ft',\n",
       " 'fun',\n",
       " 'fx',\n",
       " 'game',\n",
       " 'games',\n",
       " 'genea',\n",
       " 'geneb',\n",
       " 'general',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'gravity',\n",
       " 'groceries',\n",
       " 'group',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happens',\n",
       " 'having',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'height',\n",
       " 'help',\n",
       " 'hes',\n",
       " 'high',\n",
       " 'hline',\n",
       " 'home',\n",
       " 'hours',\n",
       " 'housework',\n",
       " 'hstep',\n",
       " 'humans',\n",
       " 'hurts',\n",
       " 'hx',\n",
       " 'id',\n",
       " 'ifstruser',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'image',\n",
       " 'important',\n",
       " 'include',\n",
       " 'increase',\n",
       " 'indium',\n",
       " 'information',\n",
       " 'input',\n",
       " 'insignificant',\n",
       " 'instead',\n",
       " 'int',\n",
       " 'integers',\n",
       " 'interested',\n",
       " 'islands',\n",
       " 'issue',\n",
       " 'ive',\n",
       " 'japanese',\n",
       " 'just',\n",
       " 'key',\n",
       " 'kids',\n",
       " 'killed',\n",
       " 'kind',\n",
       " 'kinetic',\n",
       " 'know',\n",
       " 'large',\n",
       " 'later',\n",
       " 'leaded',\n",
       " 'leg',\n",
       " 'legs',\n",
       " 'lemma',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'lgbt',\n",
       " 'life',\n",
       " 'like',\n",
       " 'limb',\n",
       " 'linked',\n",
       " 'linux',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'living',\n",
       " 'llama',\n",
       " 'loan',\n",
       " 'loans',\n",
       " 'location',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lost',\n",
       " 'loudest',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lsb',\n",
       " 'macarthur',\n",
       " 'machine',\n",
       " 'machines',\n",
       " 'main',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'management',\n",
       " 'manifolds',\n",
       " 'match',\n",
       " 'math',\n",
       " 'mathematical',\n",
       " 'mathematically',\n",
       " 'mathematics',\n",
       " 'mathequation',\n",
       " 'matte',\n",
       " 'maxboundarycellmeasure',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'mechanical',\n",
       " 'mechanics',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'men',\n",
       " 'mesh',\n",
       " 'mi',\n",
       " 'milan',\n",
       " 'million',\n",
       " 'mind',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'moved',\n",
       " 'movie',\n",
       " 'moving',\n",
       " 'muscle',\n",
       " 'muscles',\n",
       " 'nail',\n",
       " 'naturally',\n",
       " 'near',\n",
       " 'nearest',\n",
       " 'need',\n",
       " 'nested',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'node',\n",
       " 'nonorientable',\n",
       " 'normal',\n",
       " 'note',\n",
       " 'nuclear',\n",
       " 'number',\n",
       " 'oa',\n",
       " 'object',\n",
       " 'obviously',\n",
       " 'occasionally',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'old',\n",
       " 'ones',\n",
       " 'open',\n",
       " 'option',\n",
       " 'options',\n",
       " 'orcs',\n",
       " 'order',\n",
       " 'origin',\n",
       " 'original',\n",
       " 'output',\n",
       " 'paper',\n",
       " 'parent',\n",
       " 'particular',\n",
       " 'parts',\n",
       " 'party',\n",
       " 'pause',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'pc',\n",
       " 'people',\n",
       " 'person',\n",
       " 'philippines',\n",
       " 'phrase',\n",
       " 'pi',\n",
       " 'place',\n",
       " 'plane',\n",
       " 'plans',\n",
       " 'play',\n",
       " 'played',\n",
       " 'player',\n",
       " 'players',\n",
       " 'plotrange',\n",
       " 'plotted',\n",
       " 'point',\n",
       " 'points',\n",
       " 'political',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'potential',\n",
       " 'present',\n",
       " 'pretty',\n",
       " 'prevent',\n",
       " 'print',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'projective',\n",
       " 'proof',\n",
       " 'provide',\n",
       " 'public',\n",
       " 'push',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'random',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'regionunion',\n",
       " 'related',\n",
       " 'relationship',\n",
       " 'remove',\n",
       " 'required',\n",
       " 'resolution',\n",
       " 'result',\n",
       " 'return',\n",
       " 'right',\n",
       " 'righttoleft',\n",
       " 'roughly',\n",
       " 'round',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'running',\n",
       " 'russian',\n",
       " 'said',\n",
       " 'sales',\n",
       " 'satisfy',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'school',\n",
       " 'second',\n",
       " 'secure',\n",
       " 'seen',\n",
       " 'select',\n",
       " 'service',\n",
       " 'set',\n",
       " 'share',\n",
       " 'shared',\n",
       " 'shes',\n",
       " 'shoes',\n",
       " 'short',\n",
       " 'shortest',\n",
       " 'shortly',\n",
       " 'showmeshwireframe',\n",
       " 'shut',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'situation',\n",
       " 'situations',\n",
       " 'sleep',\n",
       " 'slightly',\n",
       " 'slowly',\n",
       " 'snpb',\n",
       " 'solder',\n",
       " 'solution',\n",
       " 'son',\n",
       " 'sound',\n",
       " 'spaghetti',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'square',\n",
       " 'stairs',\n",
       " 'start',\n",
       " 'started',\n",
       " 'state',\n",
       " 'stay',\n",
       " 'step',\n",
       " 'steps',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'student',\n",
       " 'stuff',\n",
       " 'sure',\n",
       " 'takes',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'task',\n",
       " 'te',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'terms',\n",
       " 'test',\n",
       " 'tex',\n",
       " 'text',\n",
       " 'thanks',\n",
       " 'theres',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'time',\n",
       " 'times',\n",
       " 'told',\n",
       " 'totally',\n",
       " 'training',\n",
       " 'tried',\n",
       " 'true',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'understand',\n",
       " 'unsure',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'valueoption',\n",
       " 'values',\n",
       " 'var',\n",
       " 'velocity',\n",
       " 'version',\n",
       " 'virtual',\n",
       " 'walking',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'watched',\n",
       " 'way',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'wife',\n",
       " 'windows',\n",
       " 'word',\n",
       " 'words',\n",
       " 'work',\n",
       " 'working',\n",
       " 'works',\n",
       " 'world',\n",
       " 'wouldnt',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'young',\n",
       " 'zero',\n",
       " 'zombies',\n",
       " 'тормоз']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_links = populate_stepback_links(question_links)\n",
    "assert len([link for link in sample_question_links if link in test_links]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [get_text(link) for link in test_links]\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "test_labels = test_data[0]\n",
    "test_corpus = test_data[1]\n",
    "\n",
    "test_matrix = tfidf.transform(test_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Decision Tree Model\n",
    "### X_train : sparse_matrix\n",
    "### y_train : labels\n",
    "### X_test : test_matrix\n",
    "### y_test : test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We don't expect this model to perform very well, given the small sample size of the training data, but this is for illustrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(sparse_matrix, labels)\n",
    "\n",
    "pred_labels = tree.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0232558139535\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Data Labels</th>\n",
       "      <th>Test Data Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>travel</td>\n",
       "      <td>academia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>interpersonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>japanese</td>\n",
       "      <td>mathematica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>travel</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>travel</td>\n",
       "      <td>unix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ux</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>travel</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>travel</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>travel</td>\n",
       "      <td>puzzling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>english</td>\n",
       "      <td>worldbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>japanese</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worldbuilding</td>\n",
       "      <td>rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>english</td>\n",
       "      <td>tex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>travel</td>\n",
       "      <td>ux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ux</td>\n",
       "      <td>rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>english</td>\n",
       "      <td>mathoverflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>travel</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>travel</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>travel</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tex</td>\n",
       "      <td>interpersonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>travel</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>travel</td>\n",
       "      <td>aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>travel</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>travel</td>\n",
       "      <td>ell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>scifi</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>travel</td>\n",
       "      <td>chess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>travel</td>\n",
       "      <td>unix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>unix</td>\n",
       "      <td>worldbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>travel</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>worldbuilding</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>unix</td>\n",
       "      <td>codegolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>travel</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>scifi</td>\n",
       "      <td>parenting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>unix</td>\n",
       "      <td>gamedev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>aviation</td>\n",
       "      <td>mathoverflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>travel</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ux</td>\n",
       "      <td>interpersonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tex</td>\n",
       "      <td>interpersonal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>codegolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dba</td>\n",
       "      <td>worldbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>travel</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Data Labels Test Data Labels\n",
       "0                 travel         academia\n",
       "2          stackoverflow    interpersonal\n",
       "4               japanese      mathematica\n",
       "5                 travel         japanese\n",
       "6                 travel             unix\n",
       "7                     ux      electronics\n",
       "8                 travel        chemistry\n",
       "9                 travel            money\n",
       "10               english              law\n",
       "11                travel         puzzling\n",
       "12               english    worldbuilding\n",
       "13              japanese           travel\n",
       "14         worldbuilding              rpg\n",
       "17               english              tex\n",
       "18                travel               ux\n",
       "19                    ux              rpg\n",
       "20               english     mathoverflow\n",
       "21                travel          history\n",
       "22                travel          physics\n",
       "23                travel         politics\n",
       "24         interpersonal              rpg\n",
       "25                   tex    interpersonal\n",
       "27                travel          english\n",
       "28                travel         aviation\n",
       "29                travel         security\n",
       "30                travel              ell\n",
       "31                 scifi        workplace\n",
       "32                travel            chess\n",
       "33                travel             unix\n",
       "34                  unix    worldbuilding\n",
       "36                travel        workplace\n",
       "38         worldbuilding          english\n",
       "39                  unix         codegolf\n",
       "40                travel           german\n",
       "41                 scifi        parenting\n",
       "42                  unix          gamedev\n",
       "43              aviation     mathoverflow\n",
       "44                travel            scifi\n",
       "45                    ux    interpersonal\n",
       "46                   tex    interpersonal\n",
       "47         interpersonal         codegolf\n",
       "48                   dba    worldbuilding\n",
       "49                travel           travel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Test Data Labels\":test_labels, \"Predicted Data Labels\":pred_labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
