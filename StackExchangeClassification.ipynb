{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scraping, Storing, Transforming, and Modelling Stack Exchange Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SEData.data import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import os\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = pd.read_csv('most_recent_by_category.csv', squeeze = True, index_col=0)\n",
    "links_already_scraped = pd.read_csv('links_scraped.csv', squeeze= True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set of 1000 observations, 15 for each of 65 categories.\n"
     ]
    }
   ],
   "source": [
    "n = 1000 # Size of data set\n",
    "l = round(n/ len(questions)) #Will create l links for each category. Also ensures balanced labels.\n",
    "print(\"Data set of \" + str(n) + ' observations, ' + str(l) + ' for each of ' + str(len(questions)) + ' categories.')\n",
    "data_links = back_generate_links(questions['url'], l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 new links not yet added to dataset\n"
     ]
    }
   ],
   "source": [
    "data_links = [i for i in data_links if i not in list(links_already_scraped)]\n",
    "print(str(len(data_links)) + \" new links not yet added to dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping (Takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data_links) > 0:\n",
    "    data = pd.DataFrame([get_text(link, pause = True) for link in data_links])\n",
    "\n",
    "\n",
    "    data.dropna(axis = 0, how = 'any', inplace = True) #Drop NAs in place.\n",
    "    data.columns = ['labels','text']\n",
    "\n",
    "    data.to_csv('Full_Data_Set.csv', mode = 'a', header=True, encoding= 'utf8', columns=['labels','text'])\n",
    "\n",
    "    links_df = pd.DataFrame({'url':data_links})\n",
    "    links_df.to_csv('links_scraped.csv', mode = 'a', header=True, encoding= 'utf8')\n",
    "else:\n",
    "    print(\"No new links to process\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8 MB'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Credit to: https://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "\n",
    "file_size('Full_Data_Set.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('5000Questions.csv', engine='python')[['labels', 'text']]\n",
    "data = pd.read_csv('Full_Data_Set.csv', engine='python')[['labels', 'text']]\n",
    "data = data[data.isin(questions.index)['labels']] # Filter out messy data, including 'None' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['academia', 'astronomy', 'aviation', 'blender', 'boardgames',\n",
       "       'chemistry', 'chess', 'chinese', 'codegolf', 'codereview',\n",
       "       'cooking', 'crypto', 'dba', 'diy', 'dsp', 'electronics', 'ell',\n",
       "       'engineering', 'english', 'ethereum', 'gamedev', 'gaming', 'german',\n",
       "       'graphicdesign', 'health', 'hinduism', 'history', 'interpersonal',\n",
       "       'japanese', 'judaism', 'law', 'lifehacks', 'math', 'mathematica',\n",
       "       'mathoverflow', 'money', 'movies', 'music', 'outdoors', 'parenting',\n",
       "       'photo', 'physics', 'politics', 'puzzling', 'rpg', 'russian',\n",
       "       'salesforce', 'scifi', 'security', 'skeptics',\n",
       "       'softwareengineering', 'stats', 'tex', 'travel', 'unix', 'ux', 'vi',\n",
       "       'workplace', 'worldbuilding', 'writers', 'cs', 'space'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size = .20) #stratify = data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = train_data['text']\n",
    "train_labels = train_data['labels']\n",
    "test_corpus = test_data['text']\n",
    "test_labels = test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I am creating a VR game Currently Im testing it on an Android device Now I when I run the application it runs smoothly and without any issue However when I add the following model  And attempt to look at it the game crashes  The model you see doesnt have any scripts on him only a transform component and an animator Has anyone tried something similar or have an idea what the issue might be Update i have also tried this following scene So i tried to isolate the character completely from my original scene So i made this   Again if i have the character in the scene it crashes if i remove the character it runs perfectly fine  Another update If i remove the animator component from the model it works fine '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][390]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                        max_features = 2000,\n",
    "                        ngram_range=(1,3))\n",
    "train_matrix = tfidf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_matrix = tfidf.transform(test_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X_train : train_matrix\n",
    "##### y_train : train_labels\n",
    "##### X_test : test_matrix\n",
    "##### y_test : test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(max_features = 'auto', n_estimators=500)\n",
    "forest.fit(train_matrix, train_labels)\n",
    "\n",
    "pred_labels = forest.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63133640553\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Cross Validation to Tune Hyper-parameters of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators' : [10, 100, 500], 'max_features' :  ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "CV_forest = GridSearchCV(estimator = forest, param_grid = param_grid, cv = 5)\n",
    "\n",
    "CV_forest.fit(train_matrix, train_labels)\n",
    "\n",
    "print(CV_forest.best_params_)\n",
    "print(CV_forest.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645161290323\n"
     ]
    }
   ],
   "source": [
    "forest = CV_forest.best_estimator_\n",
    "\n",
    "forest.fit(train_matrix, train_labels)\n",
    "\n",
    "pred_labels = forest.predict(test_matrix)\n",
    "\n",
    "print(accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50 Predicted Data Labels</th>\n",
       "      <th>50 Test Data Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>skeptics</td>\n",
       "      <td>skeptics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>law</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>dsp</td>\n",
       "      <td>dsp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>math</td>\n",
       "      <td>mathoverflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>tex</td>\n",
       "      <td>tex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>math</td>\n",
       "      <td>gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>mathematica</td>\n",
       "      <td>mathematica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>workplace</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>dsp</td>\n",
       "      <td>dsp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>crypto</td>\n",
       "      <td>crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>photo</td>\n",
       "      <td>photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>salesforce</td>\n",
       "      <td>salesforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ux</td>\n",
       "      <td>ux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>movies</td>\n",
       "      <td>stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mathematica</td>\n",
       "      <td>mathematica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>electronics</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>chinese</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>judaism</td>\n",
       "      <td>judaism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>japanese</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>crypto</td>\n",
       "      <td>crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>law</td>\n",
       "      <td>gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>chinese</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>gaming</td>\n",
       "      <td>gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>ell</td>\n",
       "      <td>ell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>writers</td>\n",
       "      <td>photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>engineering</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>diy</td>\n",
       "      <td>diy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>photo</td>\n",
       "      <td>photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>music</td>\n",
       "      <td>hinduism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>puzzling</td>\n",
       "      <td>puzzling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>boardgames</td>\n",
       "      <td>boardgames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>chemistry</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>physics</td>\n",
       "      <td>writers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>workplace</td>\n",
       "      <td>workplace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>unix</td>\n",
       "      <td>tex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>codereview</td>\n",
       "      <td>softwareengineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>worldbuilding</td>\n",
       "      <td>worldbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>mathematica</td>\n",
       "      <td>mathematica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>boardgames</td>\n",
       "      <td>mathoverflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>tex</td>\n",
       "      <td>tex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>japanese</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>parenting</td>\n",
       "      <td>parenting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>boardgames</td>\n",
       "      <td>boardgames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>law</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>writers</td>\n",
       "      <td>writers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>softwareengineering</td>\n",
       "      <td>softwareengineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>mathematica</td>\n",
       "      <td>mathematica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>health</td>\n",
       "      <td>hinduism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     50 Predicted Data Labels  50 Test Data Labels\n",
       "806                  skeptics             skeptics\n",
       "470                       law              history\n",
       "1925                      dsp                  dsp\n",
       "579                      math         mathoverflow\n",
       "1352                      tex                  tex\n",
       "2017                     math               gaming\n",
       "975               mathematica          mathematica\n",
       "2605                workplace            workplace\n",
       "309                       dsp                  dsp\n",
       "1854                   crypto               crypto\n",
       "672                     photo                photo\n",
       "2418               salesforce           salesforce\n",
       "124                        ux                   ux\n",
       "824                    movies                stats\n",
       "33                mathematica          mathematica\n",
       "2603              electronics            workplace\n",
       "222                   chinese              chinese\n",
       "516                   judaism              judaism\n",
       "1988                 ethereum             ethereum\n",
       "2133                 japanese             japanese\n",
       "1850                   crypto               crypto\n",
       "149                 astronomy            astronomy\n",
       "405                       law               gaming\n",
       "221                   chinese              chinese\n",
       "2016                   gaming               gaming\n",
       "1945                      ell                  ell\n",
       "2314                  writers                photo\n",
       "1961              engineering          engineering\n",
       "1904                      diy                  diy\n",
       "673                     photo                photo\n",
       "459                     music             hinduism\n",
       "705                  puzzling             puzzling\n",
       "191                boardgames           boardgames\n",
       "1107                chemistry            chemistry\n",
       "937                   physics              writers\n",
       "2598                workplace            workplace\n",
       "1016                     unix                  tex\n",
       "2478               codereview  softwareengineering\n",
       "923             worldbuilding        worldbuilding\n",
       "1056              mathematica          mathematica\n",
       "2225               boardgames         mathoverflow\n",
       "2532                      tex                  tex\n",
       "2245                 japanese                money\n",
       "657                 parenting            parenting\n",
       "1448               boardgames           boardgames\n",
       "538                       law                  law\n",
       "2629                  writers              writers\n",
       "815       softwareengineering  softwareengineering\n",
       "1208              mathematica          mathematica\n",
       "460                    health             hinduism"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"50 Test Data Labels\":test_labels[:50], \"50 Predicted Data Labels\":pred_labels[:50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean' 'easily' 'wear' 'alternative' 'want' 'exists' 'looks like'\n",
      " 'dont want' 'looks' 'looking' 'used' 'make' 'dont' 'know' 'like' 'finding'\n",
      " 'finished' 'fine' 'forces' 'font' 'fit' 'finally' 'form' 'formal' 'final'\n",
      " 'filter' 'finite' 'fixed' 'fix' 'follows' 'force' 'flight' 'flights'\n",
      " 'files' 'flow' 'foot' 'folder' 'food' 'folders' 'follow' 'following'\n",
      " 'floor' 'ð¾ñ' 'file' 'figure' 'factors' 'fail' 'failed' 'fairly' 'fake'\n",
      " 'fall' 'false' 'family' 'far' 'fast' 'faster' 'fat' 'father' 'feature'\n",
      " 'features' 'feed' 'feel' 'feel like' 'feeling' 'feet' 'felt' 'female'\n",
      " 'fiancã' 'field' 'fields' 'fight' 'formation' 'format' 'freedom' 'formula'\n",
      " 'generate' 'german' 'gets' 'getting' 'girl' 'given' 'gives' 'giving'\n",
      " 'goal' 'goes' 'going' 'good' 'google' 'got' 'government' 'gpgagent'\n",
      " 'gpgagent dbg' 'gpgagent dbg chan' 'granted' 'graph' 'great' 'greatly'\n",
      " 'green' 'ground' 'group']\n"
     ]
    }
   ],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names())\n",
    "tfidf_sorting = np.argsort(test_matrix.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 100\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[6 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 7 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 3 0 0]\n",
      " [0 0 0 ..., 0 6 0]\n",
      " [0 0 0 ..., 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_labels, pred_labels)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(24,24))\n",
    "plot_confusion_matrix(cnf_matrix, classes=questions.index,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('ConfusionMatrix.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
